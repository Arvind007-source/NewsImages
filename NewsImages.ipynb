import os
import zipfile
import pandas as pd
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torch.nn as nn
import torch.optim as optim

class CNNModel(nn.Module):
    def __init__(self, num_classes=2):
        super(CNNModel, self).__init__()


        # Convolutional layers
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Fully connected layers
        self.fc1 = nn.Linear(32 * 56 * 56, 512)  # Adjust input size based on your image dimensions
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(512, num_classes)

    def forward(self, x):
        # Convolutional layers
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.pool1(x)

        x = self.conv2(x)
        x = self.relu2(x)
        x = self.pool2(x)

        # Flatten before fully connected layers
        x = x.view(x.size(0), -1)

        # Fully connected layers
        x = self.fc1(x)
        x = self.relu3(x)
        x = self.fc2(x)

        return x

import torch
import torch.nn as nn

class SingleChannelWrapper(nn.Module):
    def __init__(self, model):
        super(SingleChannelWrapper, self).__init__()
        self.model = model

    def forward(self, x):
        # Duplicate the single channel to create a three-channel image
        x = x.repeat(1, 3, 1, 1)
        return self.model(x)

# Assuming model is your existing CNN model
model = CNNModel()  # Replace with your actual model

# Wrap the model with the SingleChannelWrapper
model_wrapper = SingleChannelWrapper(model)

# Now you can use model_wrapper to make predictions with single-channel images

import os
import pandas as pd
from torch.utils.data import Dataset
from torchvision import transforms
from PIL import Image
class NewsDataset(Dataset):
    def __init__(self, text_file, image_folder, transform=None):
        self.text_data = pd.read_csv(text_file, encoding='latin-1')
        self.image_folder = image_folder
        self.transform = transform

    def __len__(self):
        return len(self.text_data)

    def __getitem__(self, idx):
        text = self.text_data.iloc[idx]['hashvalue']

        # Check if 'img' column contains a valid string
        img_value = self.text_data.iloc[idx]['img']
        if pd.notna(img_value) and isinstance(img_value, str):
            image_path = os.path.join(self.image_folder, img_value)

            # Check if the image file exists
            if os.path.exists(image_path):
                image = Image.open(image_path).convert('RGB')
                if self.transform:
                    image = self.transform(image)
                return text, image
            else:
                # Handle missing image file
                # You can return a default image or skip the sample
                # Here, we return a default image (all zeros)
                default_image = Image.new('RGB', (224, 224), (0, 0, 0))
                if self.transform:
                    default_image = self.transform(default_image)
                return text, default_image
        else:
            # Handle missing or invalid image path
            # You can return a default image or skip the sample
            # Here, we return a default image (all zeros)
            default_image = Image.new('RGB', (224, 224), (0, 0, 0))
            if self.transform:
                default_image = self.transform(default_image)
            return text, default_image

import torch
import torchvision.transforms as transforms

# Assuming 'input_tensor' is your PyTorch tensor
input_tensor = torch.randn((3, 224, 224))  # Replace this with your actual tensor

# Convert the PyTorch tensor to a NumPy array
input_array = input_tensor.numpy()

# Apply the transformation
transform = transforms.ToTensor()
output_tensor = transform(input_array)

# Initialize your model, dataset, and dataloaders
model = CNNModel()
dataset = NewsDataset(text_file='/content/rt-train-textImg.csv', image_folder='images-Train', transform=output_tensor)
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Inside your training loop
k_values = [1, 5, 10, 20, 50, 100]
precision_at_k = {k: 0 for k in k_values}
num_epochs=10
for epoch in range(num_epochs):
    total_correct = 0
    total_samples = 0

    for text, image in train_loader:
        labels = torch.randint(0, 2, (len(text),))
        optimizer.zero_grad()
        outputs = model(image)

        # Convert outputs to probabilities and get predicted labels
        probabilities = torch.softmax(outputs, dim=1)
        predicted_labels = torch.argmax(probabilities, dim=1)

        # Compute accuracy
        total_correct += (predicted_labels == labels).sum().item()
        total_samples += len(labels)

        # Calculate Precision@K
        for k in k_values:
            top_k_predictions = predicted_labels.argsort(descending=True)[:k]
            precision_at_k[k] += (labels[top_k_predictions] == 1).sum().item() / k

        # Calculate loss and perform backpropagation as before

    accuracy = total_correct / total_samples
    print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}')

# Calculate and print Precision@K
for k, value in precision_at_k.items():
    precision = value / total_samples
    print(f'Precision@{k}: {precision:.4f}')

# Inside your training loop
reciprocal_ranks = []
num_epochs=10
for epoch in range(num_epochs):
    total_correct = 0
    total_samples = 0

    for text, image in train_loader:
        labels = torch.randint(0, 2, (len(text),))
        optimizer.zero_grad()
        outputs = model(image)

        # Convert outputs to probabilities and get predicted labels
        probabilities = torch.softmax(outputs, dim=1)
        predicted_labels = torch.argmax(probabilities, dim=1)

        # Compute accuracy
        total_correct += (predicted_labels == labels).sum().item()
        total_samples += len(labels)

        # Calculate reciprocal rank
        for idx, label in enumerate(labels):
            if label == 1:
                # The reciprocal rank is 1 / (position + 1)
                reciprocal_rank = 1 / (predicted_labels[idx].item() + 1)
                reciprocal_ranks.append(reciprocal_rank)

        # Calculate loss and perform backpropagation as before

    accuracy = total_correct / total_samples
    print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}')

# Calculate and print Mean Reciprocal Rank (MRR)
mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)
print(f'Mean Reciprocal Rank (MRR): {mrr:.4f}')

# Define the get_predictions function
def get_predictions(model, images):
    # Check if the list of images is not empty
    if images.numel() > 0:
        # Assuming 'images' is a list of PIL images or tensors
        # You may need to adjust this part based on your actual data
        outputs = model(images)

        # Assuming you have a function to get the predicted class or probabilities
        predictions = get_prediction(outputs,image_path)

        return predictions
    else:
        # If the list of images is empty, return an empty list
        return []

    return predictions

# Load the test dataset
test_dataset = NewsDataset(text_file="/content/rt-test-text-1.csv", image_folder='images-Test', transform=transform)

# Create a DataLoader for the test dataset
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Create and write the header to the output file
header = "News-URL\tIdOfTheMostRelevantImage\tIdOfTheSecondRelevantImage\t...\tImageID100"
output_file_path = "output.txt"
with open(output_file_path, 'w') as f:
    f.write("#header\n")

# Iterate through the test dataset and write predictions to the output file
for text, image_paths in test_loader:
    # Check if 'image_paths' tensor is not empty
    if image_paths.numel() > 0:
        predictions = get_predictions(model, image_paths)
        line = f"{text[0]}'\t'{''.join(predictions)}\n"

        with open(output_file_path, 'a') as f:
            f.write(line)
